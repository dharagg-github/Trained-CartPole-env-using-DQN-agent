{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**RL libraries that use Tensorflow as its backend**"
      ],
      "metadata": {
        "id": "BkH1Tsugkphu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Keras RL\n",
        "*   TF - Agents\n",
        "*   Tensorforce\n",
        "*   Dopamine\n",
        "*   TRFL\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-w43eMrk_G2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trained Using Keras-RL**"
      ],
      "metadata": {
        "id": "xw-jJQZU_HCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.3.0\n",
        "!pip install gym\n",
        "!pip install keras\n",
        "!pip install keras-rl2"
      ],
      "metadata": {
        "id": "ej2-LrnRknCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae9526e2-bb3d-44df-ee2b-d73814cc647f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.3.0 in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.14.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.47.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.37.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.2.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.9.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.23.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.18.5)\n",
            "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from gym) (4.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.10.0->gym) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.10.0->gym) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.9.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-rl2 in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (2.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.2.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.18.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.3.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.9.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.14.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.4.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.3.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.47.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "\n",
        "# Load the CartPole environment from the OpenAI Gym suite\n",
        "ENV_NAME = 'CartPole-v0'\n",
        "env = gym.make(ENV_NAME)"
      ],
      "metadata": {
        "id": "ekWJnb60AHQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Deep Learning Model with Keras\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "BdjD0WDGuE3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states = env.observation_space.shape\n",
        "actions = env.action_space.n\n",
        "actions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RY5tgesuSO2",
        "outputId": "8e8bd73e-ed34-4c6d-a00a-dcffbef2f73d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rl\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
        "\n",
        "# setup experience replay buffer\n",
        "memory = SequentialMemory(limit=50000, window_length=1)\n",
        "\n",
        "# setup the Linear annealed policy with the EpsGreedyQPolicy as the inner policy\n",
        "policy =  LinearAnnealedPolicy(inner_policy=  EpsGreedyQPolicy(),   # policy used to select actions\n",
        "                               attr='eps',                          # attribute in the inner policy to vary             \n",
        "                               value_max=1.0,                       # maximum value of attribute that is varying\n",
        "                               value_min=0.1,                       # minimum value of attribute that is varying\n",
        "                               value_test=0.05,                     # test if the value selected is < 0.05\n",
        "                               nb_steps=10000)                      # the number of steps between value_max and value_min\n"
      ],
      "metadata": {
        "id": "kZLMGWW_u_Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  #Feed-Forward Neural Network Model for Deep Q Learning (DQN)\n",
        "  model = Sequential()\n",
        "  #Input is 1 observation vector, and the number of observations in that vector \n",
        "  model.add(Input(shape=(1,states[0])))  \n",
        "  model.add(Flatten())\n",
        "  #Hidden layers with 24 nodes each\n",
        "  model.add(Dense(24, activation='relu'))\n",
        "  model.add(Dense(24, activation='relu'))\n",
        "  #Output is the number of actions in the action space\n",
        "  model.add(Dense(actions, activation='linear'))"
      ],
      "metadata": {
        "id": "vA2Uo6lavIxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feed-Forward Neural Network Architecture Summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLB9Mfp4vM4T",
        "outputId": "25d07f20-70e4-430c-eecf-c01d6284eb27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 24)                120       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 24)                600       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 2)                 50        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 770\n",
            "Trainable params: 770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dqn = DQNAgent(model=model,                     # Q-Network model\n",
        "               nb_actions=env.action_space.n,   # number of actions\n",
        "               memory=memory,                   # experience replay memory\n",
        "               nb_steps_warmup=25,              # how many steps are waited before starting experience replay\n",
        "               target_model_update=1e-2,        # how often the target network is updated\n",
        "               policy=policy)                   # the action selection policy\n",
        "\n",
        "# Finally, we configure and compile our agent. \n",
        "#We can use built-in tensorflow.keras Adam optimizer and evaluation metrics            \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "dqn.compile(Adam(learning_rate=1e-3), metrics=['mae','accuracy'])\n",
        "\n",
        "#Finally fit and train the agent\n",
        "history = dqn.fit(env, nb_steps=50000, visualize=False, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QoX1sAt7bZ7",
        "outputId": "a6fae05a-e3fc-4f06-9d3e-aa96228c119a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 50000 steps ...\n",
            "    21/50000: episode: 1, duration: 0.216s, episode steps:  21, steps per second:  97, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: --, mae: --, accuracy: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    52/50000: episode: 2, duration: 1.321s, episode steps:  31, steps per second:  23, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 0.382178, mae: 0.524620, accuracy: 0.602163, mean_q: 0.276348, mean_eps: 0.996535\n",
            "    85/50000: episode: 3, duration: 0.290s, episode steps:  33, steps per second: 114, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.576 [0.000, 1.000],  loss: 0.211268, mae: 0.571418, accuracy: 0.569129, mean_q: 0.642619, mean_eps: 0.993880\n",
            "   109/50000: episode: 4, duration: 0.213s, episode steps:  24, steps per second: 113, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 0.117272, mae: 0.671862, accuracy: 0.519531, mean_q: 1.039756, mean_eps: 0.991315\n",
            "   130/50000: episode: 5, duration: 0.183s, episode steps:  21, steps per second: 115, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.619 [0.000, 1.000],  loss: 0.072073, mae: 0.753317, accuracy: 0.519345, mean_q: 1.262310, mean_eps: 0.989290\n",
            "   181/50000: episode: 6, duration: 0.500s, episode steps:  51, steps per second: 102, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 0.052429, mae: 0.862318, accuracy: 0.466299, mean_q: 1.552103, mean_eps: 0.986050\n",
            "   198/50000: episode: 7, duration: 0.151s, episode steps:  17, steps per second: 112, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 0.042948, mae: 0.972396, accuracy: 0.511029, mean_q: 1.823087, mean_eps: 0.982990\n",
            "   214/50000: episode: 8, duration: 0.151s, episode steps:  16, steps per second: 106, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 0.060731, mae: 1.041475, accuracy: 0.544922, mean_q: 1.974333, mean_eps: 0.981505\n",
            "   245/50000: episode: 9, duration: 0.293s, episode steps:  31, steps per second: 106, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.419 [0.000, 1.000],  loss: 0.058130, mae: 1.134511, accuracy: 0.518145, mean_q: 2.220639, mean_eps: 0.979390\n",
            "   271/50000: episode: 10, duration: 0.255s, episode steps:  26, steps per second: 102, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 0.074464, mae: 1.244808, accuracy: 0.522837, mean_q: 2.382635, mean_eps: 0.976825\n",
            "   296/50000: episode: 11, duration: 0.230s, episode steps:  25, steps per second: 109, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.057874, mae: 1.349201, accuracy: 0.520000, mean_q: 2.672907, mean_eps: 0.974530\n",
            "   311/50000: episode: 12, duration: 0.129s, episode steps:  15, steps per second: 116, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 0.074024, mae: 1.433786, accuracy: 0.562500, mean_q: 2.805361, mean_eps: 0.972730\n",
            "   322/50000: episode: 13, duration: 0.107s, episode steps:  11, steps per second: 102, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 0.104545, mae: 1.512178, accuracy: 0.505682, mean_q: 2.968149, mean_eps: 0.971560\n",
            "   381/50000: episode: 14, duration: 0.526s, episode steps:  59, steps per second: 112, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 0.102654, mae: 1.644168, accuracy: 0.516949, mean_q: 3.176493, mean_eps: 0.968410\n",
            "   407/50000: episode: 15, duration: 0.229s, episode steps:  26, steps per second: 114, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 0.135279, mae: 1.827179, accuracy: 0.481971, mean_q: 3.495145, mean_eps: 0.964585\n",
            "   420/50000: episode: 16, duration: 0.114s, episode steps:  13, steps per second: 114, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.231 [0.000, 1.000],  loss: 0.160261, mae: 1.906927, accuracy: 0.487981, mean_q: 3.621613, mean_eps: 0.962830\n",
            "   438/50000: episode: 17, duration: 0.159s, episode steps:  18, steps per second: 113, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 0.145223, mae: 1.969402, accuracy: 0.512153, mean_q: 3.781705, mean_eps: 0.961435\n",
            "   454/50000: episode: 18, duration: 0.145s, episode steps:  16, steps per second: 111, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 0.170808, mae: 2.030881, accuracy: 0.509766, mean_q: 3.840931, mean_eps: 0.959905\n",
            "   481/50000: episode: 19, duration: 0.250s, episode steps:  27, steps per second: 108, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.153018, mae: 2.121808, accuracy: 0.512731, mean_q: 4.064517, mean_eps: 0.957970\n",
            "   544/50000: episode: 20, duration: 0.553s, episode steps:  63, steps per second: 114, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 0.161925, mae: 2.301108, accuracy: 0.518353, mean_q: 4.434967, mean_eps: 0.953920\n",
            "   556/50000: episode: 21, duration: 0.110s, episode steps:  12, steps per second: 109, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.241428, mae: 2.475086, accuracy: 0.531250, mean_q: 4.750457, mean_eps: 0.950545\n",
            "   568/50000: episode: 22, duration: 0.119s, episode steps:  12, steps per second: 101, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.186652, mae: 2.498573, accuracy: 0.505208, mean_q: 4.815376, mean_eps: 0.949465\n",
            "   594/50000: episode: 23, duration: 0.249s, episode steps:  26, steps per second: 105, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.423 [0.000, 1.000],  loss: 0.261409, mae: 2.582465, accuracy: 0.524038, mean_q: 4.947269, mean_eps: 0.947755\n",
            "   613/50000: episode: 24, duration: 0.166s, episode steps:  19, steps per second: 115, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 0.264796, mae: 2.699774, accuracy: 0.501645, mean_q: 5.221606, mean_eps: 0.945730\n",
            "   645/50000: episode: 25, duration: 0.281s, episode steps:  32, steps per second: 114, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.594 [0.000, 1.000],  loss: 0.258598, mae: 2.797499, accuracy: 0.492188, mean_q: 5.380985, mean_eps: 0.943435\n",
            "   664/50000: episode: 26, duration: 0.164s, episode steps:  19, steps per second: 116, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 0.231915, mae: 2.912217, accuracy: 0.501645, mean_q: 5.600846, mean_eps: 0.941140\n",
            "   673/50000: episode: 27, duration: 0.088s, episode steps:   9, steps per second: 103, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 0.266105, mae: 2.958193, accuracy: 0.534722, mean_q: 5.703170, mean_eps: 0.939880\n",
            "   728/50000: episode: 28, duration: 0.505s, episode steps:  55, steps per second: 109, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.564 [0.000, 1.000],  loss: 0.301480, mae: 3.080473, accuracy: 0.517614, mean_q: 5.922656, mean_eps: 0.937000\n",
            "   767/50000: episode: 29, duration: 0.359s, episode steps:  39, steps per second: 109, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.436 [0.000, 1.000],  loss: 0.303773, mae: 3.277295, accuracy: 0.489583, mean_q: 6.371235, mean_eps: 0.932770\n",
            "   793/50000: episode: 30, duration: 0.256s, episode steps:  26, steps per second: 101, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.270066, mae: 3.402902, accuracy: 0.507212, mean_q: 6.624657, mean_eps: 0.929845\n",
            "   810/50000: episode: 31, duration: 0.162s, episode steps:  17, steps per second: 105, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 0.435024, mae: 3.511983, accuracy: 0.468750, mean_q: 6.795374, mean_eps: 0.927910\n",
            "   834/50000: episode: 32, duration: 0.254s, episode steps:  24, steps per second:  95, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 0.352065, mae: 3.586391, accuracy: 0.494792, mean_q: 6.946915, mean_eps: 0.926065\n",
            "   852/50000: episode: 33, duration: 0.179s, episode steps:  18, steps per second: 101, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 0.435810, mae: 3.661395, accuracy: 0.519097, mean_q: 7.100859, mean_eps: 0.924175\n",
            "   887/50000: episode: 34, duration: 0.332s, episode steps:  35, steps per second: 106, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 0.425976, mae: 3.761666, accuracy: 0.514286, mean_q: 7.271000, mean_eps: 0.921790\n",
            "   903/50000: episode: 35, duration: 0.155s, episode steps:  16, steps per second: 103, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 0.557137, mae: 3.873837, accuracy: 0.541016, mean_q: 7.515607, mean_eps: 0.919495\n",
            "   914/50000: episode: 36, duration: 0.108s, episode steps:  11, steps per second: 102, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 0.554837, mae: 3.903594, accuracy: 0.511364, mean_q: 7.588157, mean_eps: 0.918280\n",
            "   935/50000: episode: 37, duration: 0.200s, episode steps:  21, steps per second: 105, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.619 [0.000, 1.000],  loss: 0.555937, mae: 3.984213, accuracy: 0.516369, mean_q: 7.725422, mean_eps: 0.916840\n",
            "   964/50000: episode: 38, duration: 0.270s, episode steps:  29, steps per second: 107, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.552 [0.000, 1.000],  loss: 0.344333, mae: 4.114134, accuracy: 0.546336, mean_q: 8.068471, mean_eps: 0.914590\n",
            "   994/50000: episode: 39, duration: 0.265s, episode steps:  30, steps per second: 113, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 0.373919, mae: 4.195842, accuracy: 0.558333, mean_q: 8.282135, mean_eps: 0.911935\n",
            "  1031/50000: episode: 40, duration: 0.340s, episode steps:  37, steps per second: 109, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 0.627717, mae: 4.357964, accuracy: 0.522804, mean_q: 8.496204, mean_eps: 0.908920\n",
            "  1046/50000: episode: 41, duration: 0.132s, episode steps:  15, steps per second: 114, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.484728, mae: 4.455776, accuracy: 0.535417, mean_q: 8.734217, mean_eps: 0.906580\n",
            "  1080/50000: episode: 42, duration: 0.306s, episode steps:  34, steps per second: 111, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 0.461593, mae: 4.537995, accuracy: 0.539522, mean_q: 8.930470, mean_eps: 0.904375\n",
            "  1094/50000: episode: 43, duration: 0.128s, episode steps:  14, steps per second: 110, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 0.768430, mae: 4.666719, accuracy: 0.564732, mean_q: 9.149852, mean_eps: 0.902215\n",
            "  1110/50000: episode: 44, duration: 0.167s, episode steps:  16, steps per second:  96, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 0.567784, mae: 4.687193, accuracy: 0.533203, mean_q: 9.294916, mean_eps: 0.900865\n",
            "  1150/50000: episode: 45, duration: 0.355s, episode steps:  40, steps per second: 113, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 0.682477, mae: 4.808545, accuracy: 0.526563, mean_q: 9.428862, mean_eps: 0.898345\n",
            "  1172/50000: episode: 46, duration: 0.192s, episode steps:  22, steps per second: 115, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.691850, mae: 4.925726, accuracy: 0.522727, mean_q: 9.657644, mean_eps: 0.895555\n",
            "  1193/50000: episode: 47, duration: 0.196s, episode steps:  21, steps per second: 107, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 0.548280, mae: 5.069814, accuracy: 0.526786, mean_q: 10.024098, mean_eps: 0.893620\n",
            "  1225/50000: episode: 48, duration: 0.287s, episode steps:  32, steps per second: 111, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 0.637138, mae: 5.145702, accuracy: 0.525391, mean_q: 10.172156, mean_eps: 0.891235\n",
            "  1236/50000: episode: 49, duration: 0.106s, episode steps:  11, steps per second: 103, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 0.740084, mae: 5.283192, accuracy: 0.528409, mean_q: 10.446729, mean_eps: 0.889300\n",
            "  1255/50000: episode: 50, duration: 0.200s, episode steps:  19, steps per second:  95, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 0.850865, mae: 5.337660, accuracy: 0.536184, mean_q: 10.448979, mean_eps: 0.887950\n",
            "  1280/50000: episode: 51, duration: 0.243s, episode steps:  25, steps per second: 103, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 0.630908, mae: 5.399957, accuracy: 0.525000, mean_q: 10.738859, mean_eps: 0.885970\n",
            "  1320/50000: episode: 52, duration: 0.397s, episode steps:  40, steps per second: 101, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 0.972667, mae: 5.507044, accuracy: 0.523438, mean_q: 10.806477, mean_eps: 0.883045\n",
            "  1336/50000: episode: 53, duration: 0.149s, episode steps:  16, steps per second: 108, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 0.885164, mae: 5.592003, accuracy: 0.548828, mean_q: 11.041970, mean_eps: 0.880525\n",
            "  1351/50000: episode: 54, duration: 0.149s, episode steps:  15, steps per second: 101, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.733 [0.000, 1.000],  loss: 0.747555, mae: 5.697714, accuracy: 0.514583, mean_q: 11.269056, mean_eps: 0.879130\n",
            "  1407/50000: episode: 55, duration: 0.490s, episode steps:  56, steps per second: 114, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.771668, mae: 5.845149, accuracy: 0.532366, mean_q: 11.544051, mean_eps: 0.875935\n",
            "  1456/50000: episode: 56, duration: 0.452s, episode steps:  49, steps per second: 108, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 0.813045, mae: 6.039915, accuracy: 0.534439, mean_q: 12.046434, mean_eps: 0.871210\n",
            "  1537/50000: episode: 57, duration: 0.708s, episode steps:  81, steps per second: 114, episode reward: 81.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 0.960970, mae: 6.316034, accuracy: 0.524306, mean_q: 12.517272, mean_eps: 0.865360\n",
            "  1552/50000: episode: 58, duration: 0.137s, episode steps:  15, steps per second: 110, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.741650, mae: 6.519094, accuracy: 0.552083, mean_q: 12.987126, mean_eps: 0.861040\n",
            "  1586/50000: episode: 59, duration: 0.316s, episode steps:  34, steps per second: 107, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 1.199134, mae: 6.613256, accuracy: 0.530331, mean_q: 13.103762, mean_eps: 0.858835\n",
            "  1597/50000: episode: 60, duration: 0.106s, episode steps:  11, steps per second: 104, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 1.076652, mae: 6.695233, accuracy: 0.562500, mean_q: 13.234777, mean_eps: 0.856810\n",
            "  1612/50000: episode: 61, duration: 0.139s, episode steps:  15, steps per second: 108, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.841575, mae: 6.724961, accuracy: 0.539583, mean_q: 13.467125, mean_eps: 0.855640\n",
            "  1636/50000: episode: 62, duration: 0.231s, episode steps:  24, steps per second: 104, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 1.241837, mae: 6.848566, accuracy: 0.558594, mean_q: 13.554949, mean_eps: 0.853885\n",
            "  1702/50000: episode: 63, duration: 0.608s, episode steps:  66, steps per second: 109, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 1.119465, mae: 6.949708, accuracy: 0.529356, mean_q: 13.861141, mean_eps: 0.849835\n",
            "  1716/50000: episode: 64, duration: 0.132s, episode steps:  14, steps per second: 106, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 0.902249, mae: 7.113492, accuracy: 0.553571, mean_q: 14.305159, mean_eps: 0.846235\n",
            "  1757/50000: episode: 65, duration: 0.384s, episode steps:  41, steps per second: 107, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.585 [0.000, 1.000],  loss: 0.897788, mae: 7.283968, accuracy: 0.524390, mean_q: 14.638623, mean_eps: 0.843760\n",
            "  1772/50000: episode: 66, duration: 0.142s, episode steps:  15, steps per second: 106, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 1.737417, mae: 7.455737, accuracy: 0.566667, mean_q: 14.802200, mean_eps: 0.841240\n",
            "  1804/50000: episode: 67, duration: 0.302s, episode steps:  32, steps per second: 106, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 1.721166, mae: 7.470983, accuracy: 0.541016, mean_q: 14.825296, mean_eps: 0.839125\n",
            "  1827/50000: episode: 68, duration: 0.233s, episode steps:  23, steps per second:  99, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 1.549398, mae: 7.550181, accuracy: 0.544837, mean_q: 14.953695, mean_eps: 0.836650\n",
            "  1873/50000: episode: 69, duration: 0.424s, episode steps:  46, steps per second: 109, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 1.175645, mae: 7.729631, accuracy: 0.527853, mean_q: 15.402141, mean_eps: 0.833545\n",
            "  1890/50000: episode: 70, duration: 0.156s, episode steps:  17, steps per second: 109, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 1.378900, mae: 7.836438, accuracy: 0.586397, mean_q: 15.666079, mean_eps: 0.830710\n",
            "  1960/50000: episode: 71, duration: 0.678s, episode steps:  70, steps per second: 103, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 1.053225, mae: 8.017474, accuracy: 0.535714, mean_q: 16.164288, mean_eps: 0.826795\n",
            "  1998/50000: episode: 72, duration: 0.341s, episode steps:  38, steps per second: 111, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.395 [0.000, 1.000],  loss: 1.274326, mae: 8.183895, accuracy: 0.539474, mean_q: 16.446931, mean_eps: 0.821935\n",
            "  2009/50000: episode: 73, duration: 0.101s, episode steps:  11, steps per second: 109, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 0.433517, mae: 8.446608, accuracy: 0.502841, mean_q: 17.167554, mean_eps: 0.819730\n",
            "  2033/50000: episode: 74, duration: 0.219s, episode steps:  24, steps per second: 110, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 1.035670, mae: 8.442356, accuracy: 0.532552, mean_q: 17.042538, mean_eps: 0.818155\n",
            "  2111/50000: episode: 75, duration: 0.676s, episode steps:  78, steps per second: 115, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 1.240246, mae: 8.595511, accuracy: 0.548077, mean_q: 17.391037, mean_eps: 0.813565\n",
            "  2136/50000: episode: 76, duration: 0.237s, episode steps:  25, steps per second: 105, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 1.320043, mae: 8.887188, accuracy: 0.570000, mean_q: 18.024388, mean_eps: 0.808930\n",
            "  2155/50000: episode: 77, duration: 0.181s, episode steps:  19, steps per second: 105, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 1.101271, mae: 8.908419, accuracy: 0.587171, mean_q: 18.124934, mean_eps: 0.806950\n",
            "  2191/50000: episode: 78, duration: 0.340s, episode steps:  36, steps per second: 106, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 1.577417, mae: 9.068991, accuracy: 0.548611, mean_q: 18.348621, mean_eps: 0.804475\n",
            "  2205/50000: episode: 79, duration: 0.135s, episode steps:  14, steps per second: 104, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 1.681101, mae: 9.054661, accuracy: 0.580357, mean_q: 18.280018, mean_eps: 0.802225\n",
            "  2246/50000: episode: 80, duration: 0.379s, episode steps:  41, steps per second: 108, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 1.383990, mae: 9.314074, accuracy: 0.533537, mean_q: 18.816828, mean_eps: 0.799750\n",
            "  2279/50000: episode: 81, duration: 0.292s, episode steps:  33, steps per second: 113, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 1.763587, mae: 9.523745, accuracy: 0.546402, mean_q: 19.174316, mean_eps: 0.796420\n",
            "  2341/50000: episode: 82, duration: 0.534s, episode steps:  62, steps per second: 116, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 1.124853, mae: 9.700211, accuracy: 0.535786, mean_q: 19.555104, mean_eps: 0.792145\n",
            "  2353/50000: episode: 83, duration: 0.121s, episode steps:  12, steps per second:  99, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 1.606721, mae: 9.721743, accuracy: 0.557292, mean_q: 19.616615, mean_eps: 0.788815\n",
            "  2400/50000: episode: 84, duration: 0.404s, episode steps:  47, steps per second: 116, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 1.521102, mae: 9.918664, accuracy: 0.540559, mean_q: 19.980937, mean_eps: 0.786160\n",
            "  2412/50000: episode: 85, duration: 0.114s, episode steps:  12, steps per second: 105, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 0.841681, mae: 10.236740, accuracy: 0.546875, mean_q: 20.745961, mean_eps: 0.783505\n",
            "  2439/50000: episode: 86, duration: 0.234s, episode steps:  27, steps per second: 115, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 1.605588, mae: 10.282010, accuracy: 0.515046, mean_q: 20.755398, mean_eps: 0.781750\n",
            "  2543/50000: episode: 87, duration: 0.926s, episode steps: 104, steps per second: 112, episode reward: 104.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 1.645971, mae: 10.413033, accuracy: 0.559195, mean_q: 21.032581, mean_eps: 0.775855\n",
            "  2563/50000: episode: 88, duration: 0.175s, episode steps:  20, steps per second: 114, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 1.323780, mae: 10.663610, accuracy: 0.579688, mean_q: 21.703645, mean_eps: 0.770275\n",
            "  2671/50000: episode: 89, duration: 0.923s, episode steps: 108, steps per second: 117, episode reward: 108.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.726060, mae: 10.911774, accuracy: 0.539931, mean_q: 22.021729, mean_eps: 0.764515\n",
            "  2747/50000: episode: 90, duration: 0.704s, episode steps:  76, steps per second: 108, episode reward: 76.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 1.626790, mae: 11.286924, accuracy: 0.546464, mean_q: 22.936146, mean_eps: 0.756235\n",
            "  2789/50000: episode: 91, duration: 0.383s, episode steps:  42, steps per second: 110, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 1.569734, mae: 11.733564, accuracy: 0.559524, mean_q: 23.873277, mean_eps: 0.750925\n",
            "  2837/50000: episode: 92, duration: 0.444s, episode steps:  48, steps per second: 108, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 1.605139, mae: 11.748274, accuracy: 0.543620, mean_q: 23.906239, mean_eps: 0.746875\n",
            "  2878/50000: episode: 93, duration: 0.375s, episode steps:  41, steps per second: 109, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.317 [0.000, 1.000],  loss: 1.474745, mae: 12.059211, accuracy: 0.551829, mean_q: 24.552083, mean_eps: 0.742870\n",
            "  2916/50000: episode: 94, duration: 0.354s, episode steps:  38, steps per second: 107, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 1.832371, mae: 12.103454, accuracy: 0.541941, mean_q: 24.631142, mean_eps: 0.739315\n",
            "  2991/50000: episode: 95, duration: 0.707s, episode steps:  75, steps per second: 106, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 1.605906, mae: 12.325475, accuracy: 0.553750, mean_q: 25.134597, mean_eps: 0.734230\n",
            "  3015/50000: episode: 96, duration: 0.238s, episode steps:  24, steps per second: 101, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 2.467848, mae: 12.612209, accuracy: 0.565104, mean_q: 25.631425, mean_eps: 0.729775\n",
            "  3087/50000: episode: 97, duration: 0.694s, episode steps:  72, steps per second: 104, episode reward: 72.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.578792, mae: 12.734178, accuracy: 0.570747, mean_q: 26.083744, mean_eps: 0.725455\n",
            "  3126/50000: episode: 98, duration: 0.380s, episode steps:  39, steps per second: 103, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 2.341290, mae: 13.086141, accuracy: 0.538462, mean_q: 26.655691, mean_eps: 0.720460\n",
            "  3139/50000: episode: 99, duration: 0.131s, episode steps:  13, steps per second: 100, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.231 [0.000, 1.000],  loss: 1.786774, mae: 13.212575, accuracy: 0.519231, mean_q: 27.011008, mean_eps: 0.718120\n",
            "  3286/50000: episode: 100, duration: 1.320s, episode steps: 147, steps per second: 111, episode reward: 147.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 2.065443, mae: 13.491116, accuracy: 0.557823, mean_q: 27.553051, mean_eps: 0.710920\n",
            "  3319/50000: episode: 101, duration: 0.293s, episode steps:  33, steps per second: 113, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 2.277921, mae: 14.038328, accuracy: 0.576705, mean_q: 28.534820, mean_eps: 0.702820\n",
            "  3367/50000: episode: 102, duration: 0.445s, episode steps:  48, steps per second: 108, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 1.971299, mae: 14.122603, accuracy: 0.559896, mean_q: 28.866308, mean_eps: 0.699175\n",
            "  3405/50000: episode: 103, duration: 0.348s, episode steps:  38, steps per second: 109, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.107799, mae: 14.315254, accuracy: 0.541941, mean_q: 29.180954, mean_eps: 0.695305\n",
            "  3481/50000: episode: 104, duration: 0.689s, episode steps:  76, steps per second: 110, episode reward: 76.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 2.066404, mae: 14.505523, accuracy: 0.573191, mean_q: 29.620794, mean_eps: 0.690175\n",
            "  3625/50000: episode: 105, duration: 1.261s, episode steps: 144, steps per second: 114, episode reward: 144.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 1.866623, mae: 15.021195, accuracy: 0.561415, mean_q: 30.752683, mean_eps: 0.680275\n",
            "  3660/50000: episode: 106, duration: 0.311s, episode steps:  35, steps per second: 113, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 2.030779, mae: 15.445321, accuracy: 0.565179, mean_q: 31.677507, mean_eps: 0.672220\n",
            "  3717/50000: episode: 107, duration: 0.515s, episode steps:  57, steps per second: 111, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 2.216663, mae: 15.590466, accuracy: 0.547149, mean_q: 31.903246, mean_eps: 0.668080\n",
            "  3793/50000: episode: 108, duration: 0.683s, episode steps:  76, steps per second: 111, episode reward: 76.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 2.233662, mae: 15.961055, accuracy: 0.564967, mean_q: 32.738994, mean_eps: 0.662095\n",
            "  3851/50000: episode: 109, duration: 0.568s, episode steps:  58, steps per second: 102, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 1.744434, mae: 16.436681, accuracy: 0.563578, mean_q: 33.745138, mean_eps: 0.656065\n",
            "  3958/50000: episode: 110, duration: 1.287s, episode steps: 107, steps per second:  83, episode reward: 107.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 2.314097, mae: 16.740778, accuracy: 0.569509, mean_q: 34.180126, mean_eps: 0.648640\n",
            "  4129/50000: episode: 111, duration: 1.571s, episode steps: 171, steps per second: 109, episode reward: 171.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 2.399381, mae: 17.405250, accuracy: 0.570358, mean_q: 35.631779, mean_eps: 0.636130\n",
            "  4153/50000: episode: 112, duration: 0.219s, episode steps:  24, steps per second: 110, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.745920, mae: 17.748070, accuracy: 0.535156, mean_q: 36.253935, mean_eps: 0.627355\n",
            "  4242/50000: episode: 113, duration: 0.820s, episode steps:  89, steps per second: 108, episode reward: 89.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.449 [0.000, 1.000],  loss: 3.090986, mae: 18.179494, accuracy: 0.573034, mean_q: 37.118763, mean_eps: 0.622270\n",
            "  4306/50000: episode: 114, duration: 0.560s, episode steps:  64, steps per second: 114, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 2.637401, mae: 18.326271, accuracy: 0.584961, mean_q: 37.541766, mean_eps: 0.615385\n",
            "  4317/50000: episode: 115, duration: 0.108s, episode steps:  11, steps per second: 102, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 1.399546, mae: 18.478666, accuracy: 0.602273, mean_q: 38.060781, mean_eps: 0.612010\n",
            "  4355/50000: episode: 116, duration: 0.378s, episode steps:  38, steps per second: 101, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 2.042582, mae: 18.747070, accuracy: 0.574836, mean_q: 38.503138, mean_eps: 0.609805\n",
            "  4378/50000: episode: 117, duration: 0.217s, episode steps:  23, steps per second: 106, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 2.792446, mae: 18.973590, accuracy: 0.547554, mean_q: 38.653289, mean_eps: 0.607060\n",
            "  4578/50000: episode: 118, duration: 1.847s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 2.870041, mae: 19.534280, accuracy: 0.578281, mean_q: 40.021934, mean_eps: 0.597025\n",
            "  4743/50000: episode: 119, duration: 1.495s, episode steps: 165, steps per second: 110, episode reward: 165.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.503 [0.000, 1.000],  loss: 3.282194, mae: 20.483229, accuracy: 0.589773, mean_q: 41.905824, mean_eps: 0.580600\n",
            "  4848/50000: episode: 120, duration: 0.958s, episode steps: 105, steps per second: 110, episode reward: 105.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 3.847507, mae: 21.004822, accuracy: 0.577083, mean_q: 42.816955, mean_eps: 0.568450\n",
            "  4962/50000: episode: 121, duration: 1.060s, episode steps: 114, steps per second: 108, episode reward: 114.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.656489, mae: 21.685813, accuracy: 0.592379, mean_q: 44.394892, mean_eps: 0.558595\n",
            "  4981/50000: episode: 122, duration: 0.189s, episode steps:  19, steps per second: 100, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.316 [0.000, 1.000],  loss: 5.982214, mae: 21.570799, accuracy: 0.616776, mean_q: 43.986248, mean_eps: 0.552610\n",
            "  5123/50000: episode: 123, duration: 1.277s, episode steps: 142, steps per second: 111, episode reward: 142.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 3.208236, mae: 22.410394, accuracy: 0.587368, mean_q: 45.793917, mean_eps: 0.545365\n",
            "  5227/50000: episode: 124, duration: 0.952s, episode steps: 104, steps per second: 109, episode reward: 104.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 3.215947, mae: 22.823767, accuracy: 0.613281, mean_q: 46.863975, mean_eps: 0.534295\n",
            "  5413/50000: episode: 125, duration: 1.772s, episode steps: 186, steps per second: 105, episode reward: 186.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 3.847454, mae: 23.664062, accuracy: 0.598622, mean_q: 48.429051, mean_eps: 0.521245\n",
            "  5466/50000: episode: 126, duration: 0.515s, episode steps:  53, steps per second: 103, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 3.235275, mae: 24.300873, accuracy: 0.600825, mean_q: 49.735940, mean_eps: 0.510490\n",
            "  5596/50000: episode: 127, duration: 1.213s, episode steps: 130, steps per second: 107, episode reward: 130.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 4.429617, mae: 24.579802, accuracy: 0.604808, mean_q: 50.347710, mean_eps: 0.502255\n",
            "  5796/50000: episode: 128, duration: 1.784s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 4.077098, mae: 25.482706, accuracy: 0.601562, mean_q: 52.068947, mean_eps: 0.487405\n",
            "  5859/50000: episode: 129, duration: 0.566s, episode steps:  63, steps per second: 111, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 5.239855, mae: 26.381693, accuracy: 0.593254, mean_q: 53.787660, mean_eps: 0.475570\n",
            "  5970/50000: episode: 130, duration: 0.983s, episode steps: 111, steps per second: 113, episode reward: 111.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 4.938545, mae: 26.390331, accuracy: 0.599099, mean_q: 53.918928, mean_eps: 0.467740\n",
            "  6170/50000: episode: 131, duration: 1.838s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 4.173661, mae: 27.241629, accuracy: 0.612031, mean_q: 55.583694, mean_eps: 0.453745\n",
            "  6370/50000: episode: 132, duration: 1.806s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 5.739794, mae: 28.099122, accuracy: 0.626094, mean_q: 57.449118, mean_eps: 0.435745\n",
            "  6466/50000: episode: 133, duration: 0.840s, episode steps:  96, steps per second: 114, episode reward: 96.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 3.799963, mae: 28.782505, accuracy: 0.611003, mean_q: 58.787882, mean_eps: 0.422425\n",
            "  6597/50000: episode: 134, duration: 1.179s, episode steps: 131, steps per second: 111, episode reward: 131.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 5.500926, mae: 29.194279, accuracy: 0.619513, mean_q: 59.637078, mean_eps: 0.412210\n",
            "  6797/50000: episode: 135, duration: 1.769s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.977608, mae: 29.984417, accuracy: 0.620313, mean_q: 61.175344, mean_eps: 0.397315\n",
            "  6997/50000: episode: 136, duration: 1.836s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 4.978132, mae: 30.898721, accuracy: 0.621563, mean_q: 63.127191, mean_eps: 0.379315\n",
            "  7197/50000: episode: 137, duration: 1.790s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 7.236274, mae: 31.676509, accuracy: 0.629844, mean_q: 64.509672, mean_eps: 0.361315\n",
            "  7397/50000: episode: 138, duration: 1.792s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 5.228814, mae: 32.592994, accuracy: 0.627031, mean_q: 66.393396, mean_eps: 0.343315\n",
            "  7590/50000: episode: 139, duration: 1.748s, episode steps: 193, steps per second: 110, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 7.242398, mae: 33.237660, accuracy: 0.640058, mean_q: 67.708540, mean_eps: 0.325630\n",
            "  7718/50000: episode: 140, duration: 1.172s, episode steps: 128, steps per second: 109, episode reward: 128.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 8.423452, mae: 33.917973, accuracy: 0.627441, mean_q: 69.006230, mean_eps: 0.311185\n",
            "  7918/50000: episode: 141, duration: 1.865s, episode steps: 200, steps per second: 107, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 7.862438, mae: 34.192460, accuracy: 0.639844, mean_q: 69.730475, mean_eps: 0.296425\n",
            "  8118/50000: episode: 142, duration: 1.827s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 6.626659, mae: 34.986427, accuracy: 0.647500, mean_q: 71.386690, mean_eps: 0.278425\n",
            "  8317/50000: episode: 143, duration: 1.808s, episode steps: 199, steps per second: 110, episode reward: 199.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 7.465078, mae: 35.864925, accuracy: 0.637720, mean_q: 72.986581, mean_eps: 0.260470\n",
            "  8517/50000: episode: 144, duration: 1.816s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 8.048443, mae: 36.374607, accuracy: 0.641250, mean_q: 74.083480, mean_eps: 0.242515\n",
            "  8715/50000: episode: 145, duration: 1.785s, episode steps: 198, steps per second: 111, episode reward: 198.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 6.490246, mae: 36.968280, accuracy: 0.640152, mean_q: 75.121450, mean_eps: 0.224605\n",
            "  8894/50000: episode: 146, duration: 1.648s, episode steps: 179, steps per second: 109, episode reward: 179.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 10.258229, mae: 37.609066, accuracy: 0.638443, mean_q: 76.348833, mean_eps: 0.207640\n",
            "  9055/50000: episode: 147, duration: 1.545s, episode steps: 161, steps per second: 104, episode reward: 161.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 7.992436, mae: 37.881858, accuracy: 0.639169, mean_q: 76.963813, mean_eps: 0.192340\n",
            "  9255/50000: episode: 148, duration: 1.811s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 8.439595, mae: 38.340912, accuracy: 0.646719, mean_q: 77.939005, mean_eps: 0.176095\n",
            "  9448/50000: episode: 149, duration: 1.798s, episode steps: 193, steps per second: 107, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 5.987786, mae: 38.650615, accuracy: 0.648964, mean_q: 78.748559, mean_eps: 0.158410\n",
            "  9630/50000: episode: 150, duration: 1.646s, episode steps: 182, steps per second: 111, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 8.682472, mae: 39.074743, accuracy: 0.653331, mean_q: 79.622217, mean_eps: 0.141535\n",
            "  9830/50000: episode: 151, duration: 1.771s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 7.715047, mae: 39.592490, accuracy: 0.639844, mean_q: 80.516013, mean_eps: 0.124345\n",
            " 10030/50000: episode: 152, duration: 1.751s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 8.025784, mae: 40.357102, accuracy: 0.648125, mean_q: 82.007559, mean_eps: 0.106541\n",
            " 10230/50000: episode: 153, duration: 1.801s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 7.572423, mae: 40.683452, accuracy: 0.640625, mean_q: 82.581092, mean_eps: 0.100000\n",
            " 10430/50000: episode: 154, duration: 1.867s, episode steps: 200, steps per second: 107, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 6.989655, mae: 41.378605, accuracy: 0.643750, mean_q: 84.008708, mean_eps: 0.100000\n",
            " 10630/50000: episode: 155, duration: 1.836s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 9.850986, mae: 41.341270, accuracy: 0.650625, mean_q: 83.942887, mean_eps: 0.100000\n",
            " 10830/50000: episode: 156, duration: 1.833s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.248809, mae: 42.070757, accuracy: 0.632500, mean_q: 85.225244, mean_eps: 0.100000\n",
            " 11030/50000: episode: 157, duration: 1.892s, episode steps: 200, steps per second: 106, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 9.081268, mae: 42.961165, accuracy: 0.650312, mean_q: 87.246335, mean_eps: 0.100000\n",
            " 11230/50000: episode: 158, duration: 1.881s, episode steps: 200, steps per second: 106, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 8.236854, mae: 43.247650, accuracy: 0.648906, mean_q: 87.664819, mean_eps: 0.100000\n",
            " 11430/50000: episode: 159, duration: 1.815s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 11.613897, mae: 43.649118, accuracy: 0.640781, mean_q: 88.448523, mean_eps: 0.100000\n",
            " 11630/50000: episode: 160, duration: 1.809s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 10.288139, mae: 43.859048, accuracy: 0.634062, mean_q: 88.756197, mean_eps: 0.100000\n",
            " 11830/50000: episode: 161, duration: 1.810s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 10.173116, mae: 44.789059, accuracy: 0.637500, mean_q: 90.563689, mean_eps: 0.100000\n",
            " 12030/50000: episode: 162, duration: 1.785s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 10.342489, mae: 44.467769, accuracy: 0.635938, mean_q: 90.075708, mean_eps: 0.100000\n",
            " 12230/50000: episode: 163, duration: 1.829s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 9.232051, mae: 44.928673, accuracy: 0.632188, mean_q: 91.149496, mean_eps: 0.100000\n",
            " 12430/50000: episode: 164, duration: 1.821s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 7.799956, mae: 45.781899, accuracy: 0.611719, mean_q: 92.813056, mean_eps: 0.100000\n",
            " 12630/50000: episode: 165, duration: 1.817s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 8.730653, mae: 45.867168, accuracy: 0.603594, mean_q: 93.021006, mean_eps: 0.100000\n",
            " 12830/50000: episode: 166, duration: 1.804s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 13.370822, mae: 46.324843, accuracy: 0.615625, mean_q: 93.635991, mean_eps: 0.100000\n",
            " 13030/50000: episode: 167, duration: 1.804s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 8.009454, mae: 46.621775, accuracy: 0.606406, mean_q: 94.291354, mean_eps: 0.100000\n",
            " 13230/50000: episode: 168, duration: 1.765s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 9.355511, mae: 47.119884, accuracy: 0.605938, mean_q: 95.278415, mean_eps: 0.100000\n",
            " 13430/50000: episode: 169, duration: 1.788s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.742395, mae: 47.439312, accuracy: 0.624844, mean_q: 95.951147, mean_eps: 0.100000\n",
            " 13630/50000: episode: 170, duration: 1.802s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.998213, mae: 47.660419, accuracy: 0.619375, mean_q: 96.409431, mean_eps: 0.100000\n",
            " 13830/50000: episode: 171, duration: 1.866s, episode steps: 200, steps per second: 107, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 9.540871, mae: 47.796238, accuracy: 0.592187, mean_q: 96.513376, mean_eps: 0.100000\n",
            " 14030/50000: episode: 172, duration: 1.799s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 8.734938, mae: 48.218848, accuracy: 0.604844, mean_q: 97.666696, mean_eps: 0.100000\n",
            " 14230/50000: episode: 173, duration: 1.799s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 10.764031, mae: 48.491331, accuracy: 0.606406, mean_q: 98.101565, mean_eps: 0.100000\n",
            " 14430/50000: episode: 174, duration: 1.783s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 11.839170, mae: 48.953710, accuracy: 0.601562, mean_q: 98.991220, mean_eps: 0.100000\n",
            " 14630/50000: episode: 175, duration: 1.760s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 12.949795, mae: 49.407909, accuracy: 0.603594, mean_q: 99.971567, mean_eps: 0.100000\n",
            " 14830/50000: episode: 176, duration: 1.777s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 13.670372, mae: 49.612345, accuracy: 0.599688, mean_q: 100.360576, mean_eps: 0.100000\n",
            " 15030/50000: episode: 177, duration: 1.793s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 10.801755, mae: 50.021547, accuracy: 0.600781, mean_q: 101.292100, mean_eps: 0.100000\n",
            " 15230/50000: episode: 178, duration: 1.760s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 14.612499, mae: 50.367515, accuracy: 0.605938, mean_q: 101.931991, mean_eps: 0.100000\n",
            " 15430/50000: episode: 179, duration: 1.759s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 16.596333, mae: 50.339486, accuracy: 0.622656, mean_q: 101.964477, mean_eps: 0.100000\n",
            " 15630/50000: episode: 180, duration: 1.748s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 9.254515, mae: 51.251164, accuracy: 0.614531, mean_q: 103.703445, mean_eps: 0.100000\n",
            " 15830/50000: episode: 181, duration: 1.742s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 8.397954, mae: 51.356176, accuracy: 0.611406, mean_q: 104.145808, mean_eps: 0.100000\n",
            " 16030/50000: episode: 182, duration: 1.836s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 10.677179, mae: 51.526149, accuracy: 0.605469, mean_q: 104.169515, mean_eps: 0.100000\n",
            " 16230/50000: episode: 183, duration: 1.773s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 16.033473, mae: 52.011977, accuracy: 0.610156, mean_q: 105.146073, mean_eps: 0.100000\n",
            " 16430/50000: episode: 184, duration: 1.806s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 12.854467, mae: 53.197972, accuracy: 0.610781, mean_q: 107.839024, mean_eps: 0.100000\n",
            " 16630/50000: episode: 185, duration: 1.788s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 12.295109, mae: 53.068648, accuracy: 0.613594, mean_q: 107.371404, mean_eps: 0.100000\n",
            " 16830/50000: episode: 186, duration: 1.758s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 19.604427, mae: 53.811764, accuracy: 0.630938, mean_q: 108.871321, mean_eps: 0.100000\n",
            " 17030/50000: episode: 187, duration: 1.717s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 13.098038, mae: 53.780676, accuracy: 0.625469, mean_q: 108.835408, mean_eps: 0.100000\n",
            " 17230/50000: episode: 188, duration: 1.748s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 26.646078, mae: 54.414895, accuracy: 0.628594, mean_q: 109.671251, mean_eps: 0.100000\n",
            " 17430/50000: episode: 189, duration: 1.731s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 20.336255, mae: 54.350307, accuracy: 0.614375, mean_q: 109.648297, mean_eps: 0.100000\n",
            " 17630/50000: episode: 190, duration: 1.801s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 12.231359, mae: 53.706455, accuracy: 0.627969, mean_q: 108.525006, mean_eps: 0.100000\n",
            " 17830/50000: episode: 191, duration: 1.738s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 19.688908, mae: 54.247599, accuracy: 0.635469, mean_q: 109.663563, mean_eps: 0.100000\n",
            " 18030/50000: episode: 192, duration: 1.738s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 12.938967, mae: 54.945843, accuracy: 0.642656, mean_q: 111.094935, mean_eps: 0.100000\n",
            " 18230/50000: episode: 193, duration: 1.750s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 22.057884, mae: 54.049008, accuracy: 0.633281, mean_q: 109.097686, mean_eps: 0.100000\n",
            " 18430/50000: episode: 194, duration: 1.790s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 15.184542, mae: 54.919295, accuracy: 0.638437, mean_q: 110.890431, mean_eps: 0.100000\n",
            " 18630/50000: episode: 195, duration: 1.808s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 16.364601, mae: 54.424330, accuracy: 0.643281, mean_q: 109.894949, mean_eps: 0.100000\n",
            " 18830/50000: episode: 196, duration: 1.806s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 14.577656, mae: 54.712422, accuracy: 0.651250, mean_q: 110.630950, mean_eps: 0.100000\n",
            " 19030/50000: episode: 197, duration: 1.749s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 12.187944, mae: 54.579678, accuracy: 0.654375, mean_q: 110.446994, mean_eps: 0.100000\n",
            " 19230/50000: episode: 198, duration: 1.800s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.251793, mae: 54.478916, accuracy: 0.653750, mean_q: 110.241504, mean_eps: 0.100000\n",
            " 19430/50000: episode: 199, duration: 1.789s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 15.496870, mae: 55.279202, accuracy: 0.669687, mean_q: 111.759660, mean_eps: 0.100000\n",
            " 19630/50000: episode: 200, duration: 1.750s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 14.956568, mae: 54.549159, accuracy: 0.645625, mean_q: 110.213890, mean_eps: 0.100000\n",
            " 19830/50000: episode: 201, duration: 1.774s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 20.307471, mae: 54.826423, accuracy: 0.651406, mean_q: 110.934223, mean_eps: 0.100000\n",
            " 20030/50000: episode: 202, duration: 1.835s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 16.987342, mae: 54.511522, accuracy: 0.663125, mean_q: 110.107749, mean_eps: 0.100000\n",
            " 20230/50000: episode: 203, duration: 1.811s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 14.747702, mae: 54.808099, accuracy: 0.661875, mean_q: 110.780601, mean_eps: 0.100000\n",
            " 20430/50000: episode: 204, duration: 1.829s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 19.811588, mae: 54.307284, accuracy: 0.668125, mean_q: 109.557817, mean_eps: 0.100000\n",
            " 20630/50000: episode: 205, duration: 1.806s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 10.086702, mae: 54.118713, accuracy: 0.672188, mean_q: 109.441519, mean_eps: 0.100000\n",
            " 20830/50000: episode: 206, duration: 1.801s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 19.472621, mae: 54.213715, accuracy: 0.652188, mean_q: 109.423970, mean_eps: 0.100000\n",
            " 21030/50000: episode: 207, duration: 1.854s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 15.272557, mae: 54.363151, accuracy: 0.665156, mean_q: 109.919540, mean_eps: 0.100000\n",
            " 21230/50000: episode: 208, duration: 1.772s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 26.942425, mae: 54.526452, accuracy: 0.664375, mean_q: 109.845801, mean_eps: 0.100000\n",
            " 21430/50000: episode: 209, duration: 1.762s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 15.475540, mae: 54.341178, accuracy: 0.677969, mean_q: 109.824398, mean_eps: 0.100000\n",
            " 21630/50000: episode: 210, duration: 1.781s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 18.242710, mae: 54.392915, accuracy: 0.644687, mean_q: 109.980890, mean_eps: 0.100000\n",
            " 21830/50000: episode: 211, duration: 1.772s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 12.334912, mae: 54.516124, accuracy: 0.612656, mean_q: 110.475820, mean_eps: 0.100000\n",
            " 22030/50000: episode: 212, duration: 1.773s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 20.185441, mae: 54.949712, accuracy: 0.637969, mean_q: 111.032624, mean_eps: 0.100000\n",
            " 22230/50000: episode: 213, duration: 1.826s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 15.196172, mae: 55.125940, accuracy: 0.647031, mean_q: 111.465134, mean_eps: 0.100000\n",
            " 22430/50000: episode: 214, duration: 1.816s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 30.281616, mae: 55.269546, accuracy: 0.617969, mean_q: 111.515722, mean_eps: 0.100000\n",
            " 22630/50000: episode: 215, duration: 1.836s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 15.070604, mae: 55.235874, accuracy: 0.647188, mean_q: 111.495823, mean_eps: 0.100000\n",
            " 22830/50000: episode: 216, duration: 1.824s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 22.493514, mae: 55.147825, accuracy: 0.667188, mean_q: 111.287335, mean_eps: 0.100000\n",
            " 23030/50000: episode: 217, duration: 1.811s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 21.215576, mae: 55.259574, accuracy: 0.657031, mean_q: 111.425058, mean_eps: 0.100000\n",
            " 23230/50000: episode: 218, duration: 1.794s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 18.152147, mae: 54.709563, accuracy: 0.662813, mean_q: 110.300410, mean_eps: 0.100000\n",
            " 23430/50000: episode: 219, duration: 1.784s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 13.724320, mae: 54.908554, accuracy: 0.648281, mean_q: 110.773981, mean_eps: 0.100000\n",
            " 23630/50000: episode: 220, duration: 1.793s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 9.847892, mae: 55.100925, accuracy: 0.640156, mean_q: 111.279347, mean_eps: 0.100000\n",
            " 23830/50000: episode: 221, duration: 1.808s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 26.955030, mae: 54.868430, accuracy: 0.625156, mean_q: 110.279321, mean_eps: 0.100000\n",
            " 24030/50000: episode: 222, duration: 1.796s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 31.628893, mae: 55.158683, accuracy: 0.627500, mean_q: 110.777126, mean_eps: 0.100000\n",
            " 24230/50000: episode: 223, duration: 1.846s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 29.905187, mae: 54.705442, accuracy: 0.620938, mean_q: 110.361353, mean_eps: 0.100000\n",
            " 24407/50000: episode: 224, duration: 1.584s, episode steps: 177, steps per second: 112, episode reward: 177.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 20.519993, mae: 54.887357, accuracy: 0.608051, mean_q: 110.905672, mean_eps: 0.100000\n",
            " 24607/50000: episode: 225, duration: 1.757s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 46.552233, mae: 56.201933, accuracy: 0.654687, mean_q: 112.691116, mean_eps: 0.100000\n",
            " 24807/50000: episode: 226, duration: 1.740s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 18.403861, mae: 55.777125, accuracy: 0.622344, mean_q: 112.421172, mean_eps: 0.100000\n",
            " 25007/50000: episode: 227, duration: 1.755s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 30.971468, mae: 55.422258, accuracy: 0.617188, mean_q: 111.586130, mean_eps: 0.100000\n",
            " 25207/50000: episode: 228, duration: 1.803s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 27.886237, mae: 55.645229, accuracy: 0.646563, mean_q: 111.877953, mean_eps: 0.100000\n",
            " 25407/50000: episode: 229, duration: 1.842s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 20.703645, mae: 55.879730, accuracy: 0.646406, mean_q: 112.477031, mean_eps: 0.100000\n",
            " 25607/50000: episode: 230, duration: 1.786s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 22.880842, mae: 56.188655, accuracy: 0.646563, mean_q: 113.131156, mean_eps: 0.100000\n",
            " 25807/50000: episode: 231, duration: 1.824s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 25.264215, mae: 56.083217, accuracy: 0.648594, mean_q: 112.771226, mean_eps: 0.100000\n",
            " 26007/50000: episode: 232, duration: 1.793s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 26.528915, mae: 55.537565, accuracy: 0.628906, mean_q: 111.830330, mean_eps: 0.100000\n",
            " 26207/50000: episode: 233, duration: 1.806s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 24.964021, mae: 55.247774, accuracy: 0.632969, mean_q: 110.964906, mean_eps: 0.100000\n",
            " 26407/50000: episode: 234, duration: 1.839s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 15.163309, mae: 55.397020, accuracy: 0.634844, mean_q: 111.705779, mean_eps: 0.100000\n",
            " 26607/50000: episode: 235, duration: 1.786s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 25.649396, mae: 55.211365, accuracy: 0.633125, mean_q: 111.294999, mean_eps: 0.100000\n",
            " 26807/50000: episode: 236, duration: 1.807s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 40.408251, mae: 55.434509, accuracy: 0.628750, mean_q: 111.155168, mean_eps: 0.100000\n",
            " 27007/50000: episode: 237, duration: 1.827s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 20.594947, mae: 55.138953, accuracy: 0.625156, mean_q: 111.034838, mean_eps: 0.100000\n",
            " 27207/50000: episode: 238, duration: 1.872s, episode steps: 200, steps per second: 107, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 21.314409, mae: 55.022757, accuracy: 0.645312, mean_q: 110.867013, mean_eps: 0.100000\n",
            " 27407/50000: episode: 239, duration: 1.899s, episode steps: 200, steps per second: 105, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 30.260546, mae: 55.212712, accuracy: 0.628437, mean_q: 110.960688, mean_eps: 0.100000\n",
            " 27601/50000: episode: 240, duration: 1.799s, episode steps: 194, steps per second: 108, episode reward: 194.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 26.258324, mae: 54.697622, accuracy: 0.598099, mean_q: 110.203731, mean_eps: 0.100000\n",
            " 27788/50000: episode: 241, duration: 1.748s, episode steps: 187, steps per second: 107, episode reward: 187.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 29.636053, mae: 55.733956, accuracy: 0.594418, mean_q: 112.022166, mean_eps: 0.100000\n",
            " 27988/50000: episode: 242, duration: 1.854s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 27.935940, mae: 55.688903, accuracy: 0.606094, mean_q: 112.190163, mean_eps: 0.100000\n",
            " 28188/50000: episode: 243, duration: 1.871s, episode steps: 200, steps per second: 107, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 33.744437, mae: 55.533031, accuracy: 0.593594, mean_q: 111.560075, mean_eps: 0.100000\n",
            " 28385/50000: episode: 244, duration: 1.786s, episode steps: 197, steps per second: 110, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 21.135590, mae: 55.942815, accuracy: 0.589943, mean_q: 112.757976, mean_eps: 0.100000\n",
            " 28582/50000: episode: 245, duration: 1.886s, episode steps: 197, steps per second: 104, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 29.500672, mae: 56.145347, accuracy: 0.596447, mean_q: 112.938789, mean_eps: 0.100000\n",
            " 28766/50000: episode: 246, duration: 1.748s, episode steps: 184, steps per second: 105, episode reward: 184.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 29.431245, mae: 55.521015, accuracy: 0.600543, mean_q: 111.538739, mean_eps: 0.100000\n",
            " 28954/50000: episode: 247, duration: 1.747s, episode steps: 188, steps per second: 108, episode reward: 188.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 22.638118, mae: 56.474900, accuracy: 0.593251, mean_q: 113.793069, mean_eps: 0.100000\n",
            " 29154/50000: episode: 248, duration: 1.878s, episode steps: 200, steps per second: 106, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 29.546983, mae: 56.095084, accuracy: 0.598125, mean_q: 112.980504, mean_eps: 0.100000\n",
            " 29350/50000: episode: 249, duration: 1.856s, episode steps: 196, steps per second: 106, episode reward: 196.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 23.300917, mae: 56.504033, accuracy: 0.588010, mean_q: 113.884996, mean_eps: 0.100000\n",
            " 29541/50000: episode: 250, duration: 1.707s, episode steps: 191, steps per second: 112, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 31.751650, mae: 57.032315, accuracy: 0.595713, mean_q: 114.771832, mean_eps: 0.100000\n",
            " 29739/50000: episode: 251, duration: 1.773s, episode steps: 198, steps per second: 112, episode reward: 198.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 18.727303, mae: 56.512883, accuracy: 0.602431, mean_q: 114.280054, mean_eps: 0.100000\n",
            " 29939/50000: episode: 252, duration: 1.779s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 22.090834, mae: 56.869024, accuracy: 0.599219, mean_q: 114.781289, mean_eps: 0.100000\n",
            " 30139/50000: episode: 253, duration: 1.761s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 18.834083, mae: 56.903891, accuracy: 0.604375, mean_q: 114.703570, mean_eps: 0.100000\n",
            " 30339/50000: episode: 254, duration: 1.891s, episode steps: 200, steps per second: 106, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 22.329427, mae: 57.442803, accuracy: 0.612344, mean_q: 116.022926, mean_eps: 0.100000\n",
            " 30539/50000: episode: 255, duration: 1.776s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 22.564649, mae: 57.004314, accuracy: 0.607031, mean_q: 115.063370, mean_eps: 0.100000\n",
            " 30739/50000: episode: 256, duration: 1.856s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 23.738219, mae: 57.321596, accuracy: 0.603750, mean_q: 115.766059, mean_eps: 0.100000\n",
            " 30939/50000: episode: 257, duration: 1.888s, episode steps: 200, steps per second: 106, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 19.550262, mae: 57.442432, accuracy: 0.597344, mean_q: 116.254334, mean_eps: 0.100000\n",
            " 31139/50000: episode: 258, duration: 1.858s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 15.432104, mae: 58.052125, accuracy: 0.590000, mean_q: 117.584953, mean_eps: 0.100000\n",
            " 31338/50000: episode: 259, duration: 1.833s, episode steps: 199, steps per second: 109, episode reward: 199.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 23.875635, mae: 58.240895, accuracy: 0.605057, mean_q: 117.894867, mean_eps: 0.100000\n",
            " 31535/50000: episode: 260, duration: 1.867s, episode steps: 197, steps per second: 106, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 22.266238, mae: 58.973532, accuracy: 0.583598, mean_q: 119.394679, mean_eps: 0.100000\n",
            " 31735/50000: episode: 261, duration: 1.808s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 10.522490, mae: 59.302681, accuracy: 0.592187, mean_q: 120.195840, mean_eps: 0.100000\n",
            " 31935/50000: episode: 262, duration: 1.815s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 23.275038, mae: 59.772026, accuracy: 0.605000, mean_q: 121.099932, mean_eps: 0.100000\n",
            " 32135/50000: episode: 263, duration: 1.905s, episode steps: 200, steps per second: 105, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 16.953455, mae: 60.014799, accuracy: 0.593281, mean_q: 121.567307, mean_eps: 0.100000\n",
            " 32335/50000: episode: 264, duration: 1.818s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 23.127384, mae: 60.472673, accuracy: 0.607187, mean_q: 122.298674, mean_eps: 0.100000\n",
            " 32535/50000: episode: 265, duration: 1.916s, episode steps: 200, steps per second: 104, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 23.461730, mae: 60.476255, accuracy: 0.603906, mean_q: 122.277375, mean_eps: 0.100000\n",
            " 32735/50000: episode: 266, duration: 1.864s, episode steps: 200, steps per second: 107, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 20.742545, mae: 60.597611, accuracy: 0.619062, mean_q: 122.570281, mean_eps: 0.100000\n",
            " 32932/50000: episode: 267, duration: 1.878s, episode steps: 197, steps per second: 105, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 23.729475, mae: 61.408968, accuracy: 0.597081, mean_q: 124.238918, mean_eps: 0.100000\n",
            " 33118/50000: episode: 268, duration: 1.702s, episode steps: 186, steps per second: 109, episode reward: 186.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 19.187170, mae: 61.328647, accuracy: 0.600470, mean_q: 124.155248, mean_eps: 0.100000\n",
            " 33309/50000: episode: 269, duration: 1.756s, episode steps: 191, steps per second: 109, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 25.348033, mae: 61.848093, accuracy: 0.599149, mean_q: 125.181939, mean_eps: 0.100000\n",
            " 33498/50000: episode: 270, duration: 1.726s, episode steps: 189, steps per second: 110, episode reward: 189.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 17.431427, mae: 61.921571, accuracy: 0.604167, mean_q: 125.195114, mean_eps: 0.100000\n",
            " 33698/50000: episode: 271, duration: 1.855s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 22.090925, mae: 61.907481, accuracy: 0.612656, mean_q: 125.245948, mean_eps: 0.100000\n",
            " 33898/50000: episode: 272, duration: 1.867s, episode steps: 200, steps per second: 107, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 24.059752, mae: 62.122354, accuracy: 0.612812, mean_q: 125.681530, mean_eps: 0.100000\n",
            " 34082/50000: episode: 273, duration: 1.678s, episode steps: 184, steps per second: 110, episode reward: 184.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 14.371992, mae: 62.084821, accuracy: 0.608696, mean_q: 125.960449, mean_eps: 0.100000\n",
            " 34280/50000: episode: 274, duration: 1.836s, episode steps: 198, steps per second: 108, episode reward: 198.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 14.968121, mae: 62.461309, accuracy: 0.621528, mean_q: 126.686450, mean_eps: 0.100000\n",
            " 34480/50000: episode: 275, duration: 1.802s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 25.979909, mae: 62.397690, accuracy: 0.631563, mean_q: 126.329445, mean_eps: 0.100000\n",
            " 34667/50000: episode: 276, duration: 1.756s, episode steps: 187, steps per second: 106, episode reward: 187.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 21.244927, mae: 62.202983, accuracy: 0.616310, mean_q: 125.885968, mean_eps: 0.100000\n",
            " 34853/50000: episode: 277, duration: 1.696s, episode steps: 186, steps per second: 110, episode reward: 186.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 15.187627, mae: 62.243882, accuracy: 0.618112, mean_q: 125.887980, mean_eps: 0.100000\n",
            " 35049/50000: episode: 278, duration: 1.876s, episode steps: 196, steps per second: 104, episode reward: 196.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 18.158711, mae: 62.207268, accuracy: 0.615274, mean_q: 125.957173, mean_eps: 0.100000\n",
            " 35249/50000: episode: 279, duration: 1.810s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 16.991897, mae: 62.095669, accuracy: 0.636719, mean_q: 125.650883, mean_eps: 0.100000\n",
            " 35449/50000: episode: 280, duration: 1.881s, episode steps: 200, steps per second: 106, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 17.827270, mae: 61.994365, accuracy: 0.618750, mean_q: 125.315052, mean_eps: 0.100000\n",
            " 35646/50000: episode: 281, duration: 1.783s, episode steps: 197, steps per second: 110, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 18.288442, mae: 61.948045, accuracy: 0.613261, mean_q: 125.283757, mean_eps: 0.100000\n",
            " 35841/50000: episode: 282, duration: 1.760s, episode steps: 195, steps per second: 111, episode reward: 195.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 11.268726, mae: 62.275068, accuracy: 0.605288, mean_q: 126.368366, mean_eps: 0.100000\n",
            " 36033/50000: episode: 283, duration: 1.714s, episode steps: 192, steps per second: 112, episode reward: 192.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 14.230205, mae: 62.494646, accuracy: 0.603353, mean_q: 126.713304, mean_eps: 0.100000\n",
            " 36210/50000: episode: 284, duration: 1.591s, episode steps: 177, steps per second: 111, episode reward: 177.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 13.907420, mae: 62.910212, accuracy: 0.596222, mean_q: 127.518922, mean_eps: 0.100000\n",
            " 36387/50000: episode: 285, duration: 1.577s, episode steps: 177, steps per second: 112, episode reward: 177.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 15.612373, mae: 62.518608, accuracy: 0.610169, mean_q: 126.883551, mean_eps: 0.100000\n",
            " 36571/50000: episode: 286, duration: 1.700s, episode steps: 184, steps per second: 108, episode reward: 184.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 12.443327, mae: 62.792669, accuracy: 0.602412, mean_q: 127.367633, mean_eps: 0.100000\n",
            " 36767/50000: episode: 287, duration: 1.781s, episode steps: 196, steps per second: 110, episode reward: 196.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 20.770905, mae: 62.847727, accuracy: 0.629464, mean_q: 127.192990, mean_eps: 0.100000\n",
            " 36949/50000: episode: 288, duration: 1.708s, episode steps: 182, steps per second: 107, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 9.212871, mae: 61.938875, accuracy: 0.624657, mean_q: 125.747823, mean_eps: 0.100000\n",
            " 37135/50000: episode: 289, duration: 1.711s, episode steps: 186, steps per second: 109, episode reward: 186.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 9.331185, mae: 62.493181, accuracy: 0.617440, mean_q: 126.718733, mean_eps: 0.100000\n",
            " 37318/50000: episode: 290, duration: 1.734s, episode steps: 183, steps per second: 106, episode reward: 183.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 12.874696, mae: 62.338420, accuracy: 0.613046, mean_q: 126.240646, mean_eps: 0.100000\n",
            " 37506/50000: episode: 291, duration: 1.820s, episode steps: 188, steps per second: 103, episode reward: 188.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 12.877583, mae: 62.622551, accuracy: 0.623005, mean_q: 126.843096, mean_eps: 0.100000\n",
            " 37706/50000: episode: 292, duration: 1.817s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 10.911748, mae: 62.470645, accuracy: 0.624844, mean_q: 126.546013, mean_eps: 0.100000\n",
            " 37885/50000: episode: 293, duration: 1.763s, episode steps: 179, steps per second: 102, episode reward: 179.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 16.333665, mae: 62.475953, accuracy: 0.619064, mean_q: 126.347090, mean_eps: 0.100000\n",
            " 38085/50000: episode: 294, duration: 1.874s, episode steps: 200, steps per second: 107, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 18.680664, mae: 62.623394, accuracy: 0.622344, mean_q: 126.653624, mean_eps: 0.100000\n",
            " 38276/50000: episode: 295, duration: 1.860s, episode steps: 191, steps per second: 103, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 12.250753, mae: 62.016825, accuracy: 0.626963, mean_q: 125.776554, mean_eps: 0.100000\n",
            " 38470/50000: episode: 296, duration: 1.742s, episode steps: 194, steps per second: 111, episode reward: 194.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 13.291247, mae: 62.374812, accuracy: 0.621456, mean_q: 126.497589, mean_eps: 0.100000\n",
            " 38661/50000: episode: 297, duration: 1.746s, episode steps: 191, steps per second: 109, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 18.076757, mae: 62.760966, accuracy: 0.626145, mean_q: 127.141545, mean_eps: 0.100000\n",
            " 38843/50000: episode: 298, duration: 1.726s, episode steps: 182, steps per second: 105, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 18.973226, mae: 62.635943, accuracy: 0.623626, mean_q: 126.758433, mean_eps: 0.100000\n",
            " 39027/50000: episode: 299, duration: 1.675s, episode steps: 184, steps per second: 110, episode reward: 184.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 15.565381, mae: 62.798705, accuracy: 0.624490, mean_q: 127.270061, mean_eps: 0.100000\n",
            " 39218/50000: episode: 300, duration: 1.743s, episode steps: 191, steps per second: 110, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 14.609549, mae: 61.891881, accuracy: 0.613384, mean_q: 125.300531, mean_eps: 0.100000\n",
            " 39404/50000: episode: 301, duration: 1.736s, episode steps: 186, steps per second: 107, episode reward: 186.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 14.068743, mae: 62.067854, accuracy: 0.602487, mean_q: 125.821205, mean_eps: 0.100000\n",
            " 39595/50000: episode: 302, duration: 1.779s, episode steps: 191, steps per second: 107, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 18.172132, mae: 62.006929, accuracy: 0.626800, mean_q: 125.460340, mean_eps: 0.100000\n",
            " 39778/50000: episode: 303, duration: 1.694s, episode steps: 183, steps per second: 108, episode reward: 183.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 10.061779, mae: 61.988283, accuracy: 0.614071, mean_q: 125.664040, mean_eps: 0.100000\n",
            " 39975/50000: episode: 304, duration: 1.792s, episode steps: 197, steps per second: 110, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 15.375006, mae: 62.319388, accuracy: 0.617227, mean_q: 126.015950, mean_eps: 0.100000\n",
            " 40175/50000: episode: 305, duration: 1.825s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 13.122620, mae: 61.955294, accuracy: 0.624687, mean_q: 125.347597, mean_eps: 0.100000\n",
            " 40366/50000: episode: 306, duration: 1.777s, episode steps: 191, steps per second: 107, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 10.872697, mae: 61.885853, accuracy: 0.620910, mean_q: 125.289075, mean_eps: 0.100000\n",
            " 40565/50000: episode: 307, duration: 1.843s, episode steps: 199, steps per second: 108, episode reward: 199.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 17.586959, mae: 62.152010, accuracy: 0.629397, mean_q: 125.586741, mean_eps: 0.100000\n",
            " 40764/50000: episode: 308, duration: 1.802s, episode steps: 199, steps per second: 110, episode reward: 199.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 13.235432, mae: 61.961894, accuracy: 0.625942, mean_q: 125.283843, mean_eps: 0.100000\n",
            " 40959/50000: episode: 309, duration: 1.830s, episode steps: 195, steps per second: 107, episode reward: 195.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 18.571611, mae: 61.322986, accuracy: 0.630449, mean_q: 123.820943, mean_eps: 0.100000\n",
            " 41159/50000: episode: 310, duration: 1.887s, episode steps: 200, steps per second: 106, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 10.284595, mae: 61.678525, accuracy: 0.624844, mean_q: 124.683913, mean_eps: 0.100000\n",
            " 41359/50000: episode: 311, duration: 1.834s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 12.784046, mae: 61.321663, accuracy: 0.615781, mean_q: 123.750195, mean_eps: 0.100000\n",
            " 41556/50000: episode: 312, duration: 1.923s, episode steps: 197, steps per second: 102, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 14.221824, mae: 61.617685, accuracy: 0.625635, mean_q: 124.369088, mean_eps: 0.100000\n",
            " 41756/50000: episode: 313, duration: 1.861s, episode steps: 200, steps per second: 107, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 13.284335, mae: 60.694337, accuracy: 0.625313, mean_q: 122.511792, mean_eps: 0.100000\n",
            " 41940/50000: episode: 314, duration: 1.739s, episode steps: 184, steps per second: 106, episode reward: 184.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 9.680640, mae: 61.223123, accuracy: 0.616848, mean_q: 123.885586, mean_eps: 0.100000\n",
            " 42132/50000: episode: 315, duration: 1.786s, episode steps: 192, steps per second: 107, episode reward: 192.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 17.679313, mae: 60.965284, accuracy: 0.622559, mean_q: 122.856232, mean_eps: 0.100000\n",
            " 42319/50000: episode: 316, duration: 1.669s, episode steps: 187, steps per second: 112, episode reward: 187.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 10.356248, mae: 60.886840, accuracy: 0.612132, mean_q: 122.827158, mean_eps: 0.100000\n",
            " 42497/50000: episode: 317, duration: 1.596s, episode steps: 178, steps per second: 112, episode reward: 178.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 16.121574, mae: 60.269990, accuracy: 0.616749, mean_q: 121.556420, mean_eps: 0.100000\n",
            " 42690/50000: episode: 318, duration: 1.711s, episode steps: 193, steps per second: 113, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 13.559195, mae: 60.233969, accuracy: 0.625486, mean_q: 121.405359, mean_eps: 0.100000\n",
            " 42870/50000: episode: 319, duration: 1.664s, episode steps: 180, steps per second: 108, episode reward: 180.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 13.015873, mae: 59.420379, accuracy: 0.608681, mean_q: 120.023711, mean_eps: 0.100000\n",
            " 43070/50000: episode: 320, duration: 1.866s, episode steps: 200, steps per second: 107, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 13.723172, mae: 60.509626, accuracy: 0.609219, mean_q: 122.110681, mean_eps: 0.100000\n",
            " 43251/50000: episode: 321, duration: 1.662s, episode steps: 181, steps per second: 109, episode reward: 181.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 14.366179, mae: 60.676364, accuracy: 0.607390, mean_q: 122.250623, mean_eps: 0.100000\n",
            " 43451/50000: episode: 322, duration: 1.803s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 7.198465, mae: 60.229774, accuracy: 0.625938, mean_q: 121.537935, mean_eps: 0.100000\n",
            " 43643/50000: episode: 323, duration: 1.770s, episode steps: 192, steps per second: 108, episode reward: 192.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 12.086151, mae: 59.797860, accuracy: 0.614421, mean_q: 120.551028, mean_eps: 0.100000\n",
            " 43832/50000: episode: 324, duration: 1.800s, episode steps: 189, steps per second: 105, episode reward: 189.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 9.349065, mae: 59.162326, accuracy: 0.620370, mean_q: 119.363706, mean_eps: 0.100000\n",
            " 44020/50000: episode: 325, duration: 1.774s, episode steps: 188, steps per second: 106, episode reward: 188.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 10.903018, mae: 59.330517, accuracy: 0.617021, mean_q: 119.585394, mean_eps: 0.100000\n",
            " 44212/50000: episode: 326, duration: 1.800s, episode steps: 192, steps per second: 107, episode reward: 192.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 14.449676, mae: 59.478519, accuracy: 0.618001, mean_q: 119.801711, mean_eps: 0.100000\n",
            " 44400/50000: episode: 327, duration: 1.788s, episode steps: 188, steps per second: 105, episode reward: 188.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 9.959747, mae: 58.753589, accuracy: 0.620512, mean_q: 118.493044, mean_eps: 0.100000\n",
            " 44599/50000: episode: 328, duration: 1.903s, episode steps: 199, steps per second: 105, episode reward: 199.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 9.903640, mae: 59.040342, accuracy: 0.615107, mean_q: 118.922236, mean_eps: 0.100000\n",
            " 44799/50000: episode: 329, duration: 1.852s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 8.023584, mae: 58.563277, accuracy: 0.625156, mean_q: 118.049409, mean_eps: 0.100000\n",
            " 44993/50000: episode: 330, duration: 1.780s, episode steps: 194, steps per second: 109, episode reward: 194.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 8.098867, mae: 58.601850, accuracy: 0.646263, mean_q: 118.085119, mean_eps: 0.100000\n",
            " 45185/50000: episode: 331, duration: 1.864s, episode steps: 192, steps per second: 103, episode reward: 192.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 9.939332, mae: 58.057476, accuracy: 0.628418, mean_q: 116.932689, mean_eps: 0.100000\n",
            " 45380/50000: episode: 332, duration: 1.890s, episode steps: 195, steps per second: 103, episode reward: 195.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 10.261021, mae: 57.838055, accuracy: 0.620994, mean_q: 116.687594, mean_eps: 0.100000\n",
            " 45561/50000: episode: 333, duration: 1.682s, episode steps: 181, steps per second: 108, episode reward: 181.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 15.553178, mae: 58.157125, accuracy: 0.602555, mean_q: 116.960769, mean_eps: 0.100000\n",
            " 45758/50000: episode: 334, duration: 1.829s, episode steps: 197, steps per second: 108, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 8.234571, mae: 57.793638, accuracy: 0.618496, mean_q: 116.416568, mean_eps: 0.100000\n",
            " 45956/50000: episode: 335, duration: 1.836s, episode steps: 198, steps per second: 108, episode reward: 198.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 8.701938, mae: 57.454916, accuracy: 0.603062, mean_q: 115.754105, mean_eps: 0.100000\n",
            " 46153/50000: episode: 336, duration: 1.837s, episode steps: 197, steps per second: 107, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 10.779007, mae: 58.047233, accuracy: 0.613103, mean_q: 116.963394, mean_eps: 0.100000\n",
            " 46346/50000: episode: 337, duration: 1.870s, episode steps: 193, steps per second: 103, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 11.447523, mae: 57.317283, accuracy: 0.627753, mean_q: 115.588613, mean_eps: 0.100000\n",
            " 46533/50000: episode: 338, duration: 1.829s, episode steps: 187, steps per second: 102, episode reward: 187.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 9.904185, mae: 57.822682, accuracy: 0.632353, mean_q: 116.412171, mean_eps: 0.100000\n",
            " 46728/50000: episode: 339, duration: 1.900s, episode steps: 195, steps per second: 103, episode reward: 195.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 11.850127, mae: 57.616310, accuracy: 0.623558, mean_q: 115.918637, mean_eps: 0.100000\n",
            " 46928/50000: episode: 340, duration: 1.969s, episode steps: 200, steps per second: 102, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 9.996663, mae: 57.421353, accuracy: 0.635938, mean_q: 115.496015, mean_eps: 0.100000\n",
            " 47128/50000: episode: 341, duration: 1.877s, episode steps: 200, steps per second: 107, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 9.166210, mae: 57.158966, accuracy: 0.636719, mean_q: 115.041070, mean_eps: 0.100000\n",
            " 47328/50000: episode: 342, duration: 1.892s, episode steps: 200, steps per second: 106, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 11.472091, mae: 56.505225, accuracy: 0.639219, mean_q: 113.722920, mean_eps: 0.100000\n",
            " 47525/50000: episode: 343, duration: 1.806s, episode steps: 197, steps per second: 109, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 9.285493, mae: 56.892251, accuracy: 0.634042, mean_q: 114.629746, mean_eps: 0.100000\n",
            " 47725/50000: episode: 344, duration: 1.852s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 5.044864, mae: 56.754988, accuracy: 0.632031, mean_q: 114.287354, mean_eps: 0.100000\n",
            " 47925/50000: episode: 345, duration: 1.902s, episode steps: 200, steps per second: 105, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 6.615167, mae: 56.364443, accuracy: 0.638125, mean_q: 113.581989, mean_eps: 0.100000\n",
            " 48120/50000: episode: 346, duration: 1.829s, episode steps: 195, steps per second: 107, episode reward: 195.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 12.099119, mae: 55.945089, accuracy: 0.625801, mean_q: 112.552750, mean_eps: 0.100000\n",
            " 48320/50000: episode: 347, duration: 1.904s, episode steps: 200, steps per second: 105, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 9.355757, mae: 55.698345, accuracy: 0.635625, mean_q: 112.132618, mean_eps: 0.100000\n",
            " 48508/50000: episode: 348, duration: 1.800s, episode steps: 188, steps per second: 104, episode reward: 188.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 11.275851, mae: 55.697601, accuracy: 0.617686, mean_q: 111.969356, mean_eps: 0.100000\n",
            " 48708/50000: episode: 349, duration: 1.952s, episode steps: 200, steps per second: 102, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 8.030688, mae: 56.140595, accuracy: 0.629375, mean_q: 112.994164, mean_eps: 0.100000\n",
            " 48908/50000: episode: 350, duration: 1.894s, episode steps: 200, steps per second: 106, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 8.493995, mae: 56.080353, accuracy: 0.618125, mean_q: 113.124053, mean_eps: 0.100000\n",
            " 49108/50000: episode: 351, duration: 1.950s, episode steps: 200, steps per second: 103, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 7.185409, mae: 55.257868, accuracy: 0.642031, mean_q: 111.299255, mean_eps: 0.100000\n",
            " 49308/50000: episode: 352, duration: 1.900s, episode steps: 200, steps per second: 105, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 9.180665, mae: 55.145984, accuracy: 0.625469, mean_q: 111.012749, mean_eps: 0.100000\n",
            " 49508/50000: episode: 353, duration: 1.849s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 7.849369, mae: 54.672740, accuracy: 0.636094, mean_q: 110.174193, mean_eps: 0.100000\n",
            " 49708/50000: episode: 354, duration: 1.880s, episode steps: 200, steps per second: 106, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 11.142183, mae: 54.920420, accuracy: 0.629531, mean_q: 110.461302, mean_eps: 0.100000\n",
            " 49908/50000: episode: 355, duration: 1.958s, episode steps: 200, steps per second: 102, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 7.303156, mae: 54.699070, accuracy: 0.638750, mean_q: 110.192736, mean_eps: 0.100000\n",
            "done, took 460.269 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Visualize the history for number of Training episode steps of the Cart Pole Game\n",
        "plt.figure(figsize = (18,10))\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jRvHOzEWbZsE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "83432fa4-545f-4fe8-9f08-2a40a8746121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, evaluate and test our algorithm for 20 episodes.\n",
        "dqn.test(env, nb_episodes=20, visualize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdowKLfDScuW",
        "outputId": "27a90a48-38f8-43e2-d4d3-dafcb389d9b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6fdb115a50>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training with TF-Agent**"
      ],
      "metadata": {
        "id": "7nV4e3-k5dju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygame\n",
        "!pip install 'imageio==2.4.0'\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install tf-agents[reverb]\n",
        "!pip install pyglet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQNSQmSI5ff3",
        "outputId": "cb057dd8-908a-466a-ed0f-97d6622f49c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio==2.4.0 in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.0) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.0) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf-agents[reverb] in /usr/local/lib/python3.7/dist-packages (0.13.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (7.1.2)\n",
            "Requirement already satisfied: pygame==2.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.21.6)\n",
            "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.23.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.5.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (3.17.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (4.1.1)\n",
            "Requirement already satisfied: tensorflow-probability>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.16.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.2.0)\n",
            "Requirement already satisfied: rlds in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.1.5)\n",
            "Requirement already satisfied: dm-reverb~=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.8.0)\n",
            "Requirement already satisfied: tensorflow~=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (2.9.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from dm-reverb~=0.8.0->tf-agents[reverb]) (0.1.7)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.7/dist-packages (from dm-reverb~=0.8.0->tf-agents[reverb]) (1.3.9)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.10.0->gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (3.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (1.12)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (2.9.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (1.47.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (0.26.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (0.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (57.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (14.0.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (2.10.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (21.3)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (2.9.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-agents[reverb]) (2.9.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-agents[reverb]) (0.37.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-agents[reverb]) (3.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.16.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow~=2.9.0->tf-agents[reverb]) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyglet in /usr/local/lib/python3.7/dist-packages (1.5.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import base64\n",
        "import imageio\n",
        "import IPython\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import pyvirtualdisplay\n",
        "import reverb\n",
        "import gym\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.drivers import py_driver\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.networks import sequential\n",
        "from tf_agents.policies import py_tf_eager_policy\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.replay_buffers import reverb_replay_buffer\n",
        "from tf_agents.replay_buffers import reverb_utils\n",
        "from tf_agents.trajectories import trajectory\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.utils import common"
      ],
      "metadata": {
        "id": "6-39HaY582wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_name = 'CartPole-v0'\n",
        "env = suite_gym.load(env_name)"
      ],
      "metadata": {
        "id": "ULTlwlAq82y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_iterations = 10000 # @param {type:\"integer\"}\n",
        "\n",
        "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
        "collect_steps_per_iteration = 1 # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "\n",
        "batch_size = 64  # @param {type:\"integer\"}\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "num_eval_episodes = 20  # @param {type:\"integer\"}\n",
        "eval_interval = 1000  # @param {type:\"integer\"}"
      ],
      "metadata": {
        "id": "zp-yFklW821q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_py_env = suite_gym.load(env_name)\n",
        "eval_py_env = suite_gym.load(env_name)\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
      ],
      "metadata": {
        "id": "8Spk-Ed0824F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc_layer_params = (100, 50)\n",
        "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
        "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
        "\n",
        "# Define a helper function to create Dense layers configured with the right\n",
        "# activation and kernel initializer.\n",
        "def dense_layer(num_units):\n",
        "  return tf.keras.layers.Dense(\n",
        "      num_units,\n",
        "      activation=tf.keras.activations.relu,\n",
        "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
        "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
        "\n",
        "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
        "# with `num_actions` units to generate one q_value per available action as\n",
        "# its output.\n",
        "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
        "q_values_layer = tf.keras.layers.Dense(\n",
        "    num_actions,\n",
        "    activation=None,\n",
        "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
        "        minval=-0.03, maxval=0.03),\n",
        "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
        "q_net = sequential.Sequential(dense_layers + [q_values_layer])"
      ],
      "metadata": {
        "id": "tYOWCh_L826Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()"
      ],
      "metadata": {
        "id": "e591NBx9828o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_policy = agent.policy\n",
        "collect_policy = agent.collect_policy\n",
        "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
        "                                                train_env.action_spec())"
      ],
      "metadata": {
        "id": "dka6Qath82_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "  total_return = 0.0\n",
        "  for _ in range(num_episodes):\n",
        "\n",
        "    time_step = environment.reset()\n",
        "    episode_return = 0.0\n",
        "\n",
        "    while not time_step.is_last():\n",
        "      action_step = policy.action(time_step)\n",
        "      time_step = environment.step(action_step.action)\n",
        "      episode_return += time_step.reward\n",
        "    total_return += episode_return\n",
        "\n",
        "  avg_return = total_return / num_episodes\n",
        "  return avg_return.numpy()[0]"
      ],
      "metadata": {
        "id": "awiy0-3883CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSLQPZME83E0",
        "outputId": "e40406bb-16cb-44b7-dc83-1852699e4b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25.9"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table_name = 'uniform_table'\n",
        "replay_buffer_signature = tensor_spec.from_spec(\n",
        "      agent.collect_data_spec)\n",
        "replay_buffer_signature = tensor_spec.add_outer_dim(\n",
        "    replay_buffer_signature)\n",
        "\n",
        "table = reverb.Table(\n",
        "    table_name,\n",
        "    max_size=replay_buffer_max_length,\n",
        "    sampler=reverb.selectors.Uniform(),\n",
        "    remover=reverb.selectors.Fifo(),\n",
        "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
        "    signature=replay_buffer_signature)\n",
        "\n",
        "reverb_server = reverb.Server([table])\n",
        "\n",
        "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
        "    agent.collect_data_spec,\n",
        "    table_name=table_name,\n",
        "    sequence_length=2,\n",
        "    local_server=reverb_server)\n",
        "\n",
        "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
        "  replay_buffer.py_client,\n",
        "  table_name,\n",
        "  sequence_length=2)"
      ],
      "metadata": {
        "id": "BmzlyX9U83Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.collect_data_spec\n",
        "agent.collect_data_spec._fields"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4f7pPCV83KK",
        "outputId": "27b44305-0081-4456-b426-ade771caffd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('step_type',\n",
              " 'observation',\n",
              " 'action',\n",
              " 'policy_info',\n",
              " 'next_step_type',\n",
              " 'reward',\n",
              " 'discount')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "py_driver.PyDriver(\n",
        "    env,\n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "      random_policy, use_tf_function=True),\n",
        "    [rb_observer],\n",
        "    max_steps=initial_collect_steps).run(train_py_env.reset())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk-GFcw383Nd",
        "outputId": "eeea6b10-b3e2-4e00-eecc-01df643d102f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TimeStep(\n",
              " {'discount': array(0., dtype=float32),\n",
              "  'observation': array([ 0.15134448,  1.1901444 , -0.21252759, -1.9044948 ], dtype=float32),\n",
              "  'reward': array(1., dtype=float32),\n",
              "  'step_type': array(2, dtype=int32)}), ())"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset generates trajectories with shape [Bx2x...]\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "dataset\n",
        "iterator = iter(dataset)\n",
        "print(iterator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpYwTmae9gwh",
        "outputId": "0db2f594-44b3-4033-a701-d5c1fbb50fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f856bfc28d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  %%time\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step.\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "# Reset the environment.\n",
        "time_step = train_py_env.reset()\n",
        "\n",
        "# Create a driver to collect experience.\n",
        "collect_driver = py_driver.PyDriver(\n",
        "    env,\n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "      agent.collect_policy, use_tf_function=True),\n",
        "    [rb_observer],\n",
        "    max_steps=collect_steps_per_iteration)\n",
        "\n",
        "for _ in range(num_iterations):\n",
        "\n",
        "  # Collect a few steps and save to the replay buffer.\n",
        "  time_step, _ = collect_driver.run(time_step)\n",
        "\n",
        "  # Sample a batch of data from the buffer and update the agent's network.\n",
        "  experience, unused_info = next(iterator)\n",
        "  train_loss = agent.train(experience).loss\n",
        "\n",
        "  step = agent.train_step_counter.numpy()\n",
        "\n",
        "  if step % log_interval == 0:\n",
        "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "  if step % eval_interval == 0:\n",
        "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "    returns.append(avg_return)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77sywrWX9gzm",
        "outputId": "38a2cb6f-c47f-4142-8e54-cd525258b9eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.foldr(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 200: loss = 24.732250213623047\n",
            "step = 400: loss = 1.7360987663269043\n",
            "step = 600: loss = 30.060609817504883\n",
            "step = 800: loss = 89.10052490234375\n",
            "step = 1000: loss = 67.4189224243164\n",
            "step = 1000: Average Return = 92.0\n",
            "step = 1200: loss = 294.8477478027344\n",
            "step = 1400: loss = 203.28744506835938\n",
            "step = 1600: loss = 58.353050231933594\n",
            "step = 1800: loss = 119.88228607177734\n",
            "step = 2000: loss = 602.300537109375\n",
            "step = 2000: Average Return = 51.0\n",
            "step = 2200: loss = 95.66868591308594\n",
            "step = 2400: loss = 46.98866271972656\n",
            "step = 2600: loss = 29.3885440826416\n",
            "step = 2800: loss = 33.58258056640625\n",
            "step = 3000: loss = 16.691349029541016\n",
            "step = 3000: Average Return = 77.8499984741211\n",
            "step = 3200: loss = 13.518373489379883\n",
            "step = 3400: loss = 24.236507415771484\n",
            "step = 3600: loss = 15.8800048828125\n",
            "step = 3800: loss = 16.19216537475586\n",
            "step = 4000: loss = 15.823516845703125\n",
            "step = 4000: Average Return = 182.64999389648438\n",
            "step = 4200: loss = 16.447429656982422\n",
            "step = 4400: loss = 7.367780685424805\n",
            "step = 4600: loss = 28.37320327758789\n",
            "step = 4800: loss = 10.257041931152344\n",
            "step = 5000: loss = 46.03394317626953\n",
            "step = 5000: Average Return = 198.3000030517578\n",
            "step = 5200: loss = 22.785564422607422\n",
            "step = 5400: loss = 35.40253448486328\n",
            "step = 5600: loss = 50.44752502441406\n",
            "step = 5800: loss = 57.59840393066406\n",
            "step = 6000: loss = 58.046722412109375\n",
            "step = 6000: Average Return = 200.0\n",
            "step = 6200: loss = 18.728784561157227\n",
            "step = 6400: loss = 29.84893798828125\n",
            "step = 6600: loss = 86.350830078125\n",
            "step = 6800: loss = 13.659553527832031\n",
            "step = 7000: loss = 67.09120178222656\n",
            "step = 7000: Average Return = 200.0\n",
            "step = 7200: loss = 106.10042572021484\n",
            "step = 7400: loss = 58.781890869140625\n",
            "step = 7600: loss = 3551.31201171875\n",
            "step = 7800: loss = 51.34828567504883\n",
            "step = 8000: loss = 65.00470733642578\n",
            "step = 8000: Average Return = 200.0\n",
            "step = 8200: loss = 70.7041015625\n",
            "step = 8400: loss = 758.804443359375\n",
            "step = 8600: loss = 1067.1329345703125\n",
            "step = 8800: loss = 68778.2890625\n",
            "step = 9000: loss = 545.7938842773438\n",
            "step = 9000: Average Return = 200.0\n",
            "step = 9200: loss = 1039.6292724609375\n",
            "step = 9400: loss = 978.1467895507812\n",
            "step = 9600: loss = 48942.54296875\n",
            "step = 9800: loss = 302.3236999511719\n",
            "step = 10000: loss = 42674.05859375\n",
            "step = 10000: Average Return = 200.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "MYofi6dC9g2G",
        "outputId": "44c34065-450f-4362-d352-18a931dacf1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.657499599456786, 250.0)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result**"
      ],
      "metadata": {
        "id": "FB823Fw09pph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes they Differ.."
      ],
      "metadata": {
        "id": "jph6lYyWGwQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The performance of the TF-Agents library is good and quick when compared to the Keras-RL library.\n",
        "*   It is obvious that training TF -Agents requires less iterations. When you look at the graph, the agent eventually reaches its maximum reward and stays constant, however Keras RL is not stable and does not behave in this way.\n",
        "*   This might be the result of a lack of updates, which is not the case with TF- Agents, which was released recently and has more advantages than KerasRL.\n",
        "And mainly TF-Agents has TensorBoard utility.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jqPN9jBl9s48"
      }
    }
  ]
}